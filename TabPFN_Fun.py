import pandas as pd
import numpy as np
# Scikit-learn imports
from sklearn.model_selection import KFold, cross_val_score
from sklearn.metrics import mean_squared_error, make_scorer
from scipy.stats import spearmanr
from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_regression
import pandas.api.types as ptypes
# from sklearn.multioutput import MultiOutputRegressor # Removed
from sklearn import clone # For cloning pipeline in averaging loop
# TabPFN specific import
try:
    # Using AutoTabPFNRegressor as requested
    from tabpfn import TabPFNRegressor # Still useful for context/type hints if needed
    from tabpfn_extensions.post_hoc_ensembles.sklearn_interface import AutoTabPFNRegressor
except ImportError:
    print("Please install tabpfn and potentially tabpfn-extensions:")
    print("pip install tabpfn")
    print("pip install git+https://github.com/automl/TabPFN-extensions.git") # Needed for AutoTabPFNRegressor
    exit()
# Other necessary imports
import warnings
import re
import datetime
import logging
import torch # For checking CUDA
import gc # For garbage collection

warnings.filterwarnings('ignore')

# --- Configuration ---
DATA_DIR = './' # <<<--- !!! ADAPT THIS PATH !!!
METADATA_FILE = f'{DATA_DIR}metadata.csv'
TRAIN_FEATURES_FILE = f'{DATA_DIR}train_features.csv'
TRAIN_OUTCOMES_FILE = f'{DATA_DIR}train_outcomes_functional.csv' # Functional track
TEST_FEATURES_FILE = f'{DATA_DIR}test_features.csv'
SUBMISSION_TEMPLATE_FILE = f'{DATA_DIR}test_outcomes_Fun_template_update.csv' # Functional track template

# --- External Future Motor Score Configuration ---
USE_FUTURE_MOTOR_FEATURES = True
EXTERNAL_PREDS_FILE = f'{DATA_DIR}submission_TabPFN_MultiOutput_v6_FE_native_nan_Avg5_NoCV_2025-04-17_21-38-13.csv'
TRAIN_OUTCOMES_MOTOR_FILE = f'{DATA_DIR}train_outcomes_MS.csv'

# --- Manual Feature Group Selection Configuration ---
SELECT_METADATA = True
SELECT_WEEK1_ORIGINAL = True
SELECT_FE_FEATURES = True # Use features generated by engineer_features (from Wk1)
SELECT_TARGET_TIME = True
SELECT_FUTURE_MOTOR_FEATURES = True # Use features from external predictions/actuals (only if USE_FUTURE_MOTOR_FEATURES is also True)

# --- Automated Feature Selection Configuration ---
DO_FEATURE_SELECTION = True   # Enable automated feature selection: if True, the pipeline will perform feature reduction.
VAR_THRESH = 0.01             # Variance Threshold: removes numeric features with variance below 0.01; low-variance features are less informative.
CORR_THRESH = 0.93            # Correlation Threshold: drops one feature from any pair with correlation > 0.95 to reduce redundancy.
UNIVARIATE_K = 75             # Univariate Selection: selects the top 75 features based on f_regression scores (if k is not 'all').

# --- Model Configuration ---
MODEL_TYPE = 'AutoTabPFN'
PERFORM_CV = False
CV_FOLDS = 5

# --- Averaging Configuration ---
PERFORM_AVERAGING = True
N_AVERAGING_RUNS = 5
BASE_RANDOM_STATE = 42

# --- AutoTabPFN Configuration ---
AUTO_TABPFN_TIME_BUDGET_SECONDS = 3600
TABPFN_DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
AUTOTABPFN_PARAMS = {'device': TABPFN_DEVICE, 'max_time': AUTO_TABPFN_TIME_BUDGET_SECONDS}

# --- Setup Logging ---
log_file = 'Functional_Metrics_AutoTabPFN_AvgFE_AutoFS_Ext.log' # AutoFS + Ext
cv_mode_str = f"{CV_FOLDS}FoldCV" if (PERFORM_CV and not PERFORM_AVERAGING) else "NoCV"
avg_mode_str = f"Avg{N_AVERAGING_RUNS}" if PERFORM_AVERAGING else "SingleRun"
ms_str = f"M{int(SELECT_METADATA)}_W{int(SELECT_WEEK1_ORIGINAL)}_F{int(SELECT_FE_FEATURES)}_T{int(SELECT_TARGET_TIME)}_E{int(SELECT_FUTURE_MOTOR_FEATURES and USE_FUTURE_MOTOR_FEATURES)}"
fs_str = f"AutoFS{int(DO_FEATURE_SELECTION)}"
base_model_name = f"{MODEL_TYPE}_SingleOutput_v6_FuncPred_{ms_str}_{fs_str}"
model_name = f"{base_model_name}_{avg_mode_str}_{cv_mode_str}"
run_timestamp = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
run_id = f"{model_name}_{run_timestamp}"
SUBMISSION_OUTPUT_FILE = f'{DATA_DIR}submission_{run_id}.csv'

# (Logger setup remains the same)
logger = logging.getLogger(run_id); logger.setLevel(logging.INFO)
if not logger.handlers:
    fh = logging.FileHandler(log_file); fh.setLevel(logging.INFO)
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')
    fh.setFormatter(formatter); logger.addHandler(fh)
    sh = logging.StreamHandler(); sh.setLevel(logging.INFO); sh.setFormatter(formatter); logger.addHandler(sh)

logger.info(f"--- Starting Run: {run_id} ---")
logger.info(f"Predicting Functional Outcome (Benzel Score)")
logger.info(f"Selected Model Type: {MODEL_TYPE}")
logger.info(f"Manual Averaging Enabled: {PERFORM_AVERAGING} (Runs: {N_AVERAGING_RUNS if PERFORM_AVERAGING else 1})")
logger.info(f"Cross-Validation Enabled: {PERFORM_CV and not PERFORM_AVERAGING}")
logger.info(f"Base AutoTabPFN Parameters: {AUTOTABPFN_PARAMS}")
logger.info(f"Manual Feature Selection: Metadata={SELECT_METADATA}, Week1={SELECT_WEEK1_ORIGINAL}, FE_Wk1={SELECT_FE_FEATURES}, TargetTime={SELECT_TARGET_TIME}, FutureMotor={SELECT_FUTURE_MOTOR_FEATURES and USE_FUTURE_MOTOR_FEATURES}")
logger.info(f"Automated Feature Selection Enabled: {DO_FEATURE_SELECTION} (VarThresh={VAR_THRESH}, CorrThresh={CORR_THRESH}, K={UNIVARIATE_K})")
if USE_FUTURE_MOTOR_FEATURES:
    logger.info(f"External Predictions File (Test): {EXTERNAL_PREDS_FILE}")
    logger.info(f"External Outcomes File (Train): {TRAIN_OUTCOMES_MOTOR_FILE}")
logger.info(f"Data Directory: {DATA_DIR}")
logger.info(f"Output Submission File: {SUBMISSION_OUTPUT_FILE}")
if TABPFN_DEVICE == 'cuda': logger.info("CUDA (GPU) available.")
else: logger.info("CUDA (GPU) not available, using CPU.")


# --- Define Spearman Scorer ---
def spearman_corr(y_true, y_pred):
    if np.all(np.isnan(y_pred)) or np.all(np.isnan(y_true)): return 0.0
    y_true_arr = np.array(y_true); y_pred_arr = np.array(y_pred)
    if y_true_arr.ndim > 1 or y_pred_arr.ndim > 1: y_true_arr = y_true_arr.squeeze(); y_pred_arr = y_pred_arr.squeeze()
    if np.std(y_pred_arr) == 0 or np.std(y_true_arr) == 0: return 1.0 if np.all(y_true_arr == y_pred_arr) else 0.0
    corr, _ = spearmanr(y_true_arr, y_pred_arr); return corr if not np.isnan(corr) else 0.0
spearman_scorer = make_scorer(spearman_corr, greater_is_better=True)

# --- Automated Feature Selection Function ---
def select_features(X_train, y_train, X_test, features,
                    var_thresh=0.01,
                    corr_thresh=0.95,
                    k='all'):
    logger.info(f"Starting feature selection on {len(features)} features...")
    numeric_feats = [f for f in features if ptypes.is_numeric_dtype(X_train[f])]
    non_numeric_feats = [f for f in features if f not in numeric_feats]
    logger.info(f"Found {len(numeric_feats)} numeric and {len(non_numeric_feats)} non-numeric features.")
    if not numeric_feats: logger.warning("No numeric features for selection."); return X_train, X_test, features
    X_train_num = X_train[numeric_feats].copy(); X_test_num  = X_test[numeric_feats].copy()
    logger.info("Imputing numeric features (median) for selection calculations..."); imp = SimpleImputer(strategy='median')
    X_train_num_imp = pd.DataFrame(imp.fit_transform(X_train_num), columns=numeric_feats, index=X_train.index)
    X_test_num_imp = pd.DataFrame(imp.transform(X_test_num), columns=numeric_feats, index=X_test.index)
    initial_numeric_count = len(numeric_feats)
    logger.info(f"Applying Variance Threshold (threshold={var_thresh})...")
    vt = VarianceThreshold(threshold=var_thresh); vt.fit(X_train_num_imp); mask_var = vt.get_support()
    feats_var = [f for f, keep in zip(numeric_feats, mask_var) if keep]; X_train_v = X_train_num_imp[feats_var].copy()
    logger.info(f"Variance Threshold kept {len(feats_var)}/{initial_numeric_count} numeric features.")
    if not feats_var: logger.warning("Variance Threshold removed all numeric. Returning only non-numeric."); feats_final = non_numeric_feats; return X_train[feats_final].copy(), X_test[feats_final].copy(), feats_final
    logger.info(f"Applying Correlation Threshold (threshold={corr_thresh})..."); corr_matrix = X_train_v.corr().abs()
    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
    to_drop = [column for column in upper.columns if any(upper[column] > corr_thresh)]; feats_uncorr = [f for f in feats_var if f not in to_drop]
    X_train_u = X_train_v[feats_uncorr].copy(); logger.info(f"Correlation Threshold kept {len(feats_uncorr)}/{len(feats_var)} numeric features.")
    if not feats_uncorr: logger.warning("Correlation Threshold removed all numeric. Returning only non-numeric."); feats_final = non_numeric_feats; return X_train[feats_final].copy(), X_test[feats_final].copy(), feats_final
    if k != 'all' and isinstance(k, int) and k > 0:
        k_final = min(k, X_train_u.shape[1]); logger.info(f"Applying Univariate Selection (f_regression, k={k_final})...")
        skb = SelectKBest(score_func=f_regression, k=k_final); skb.fit(X_train_u, y_train); mask_k = skb.get_support()
        feats_sel_num = [f for f, keep in zip(feats_uncorr, mask_k) if keep]; logger.info(f"Univariate Selection kept {len(feats_sel_num)}/{len(feats_uncorr)} numeric features.")
    else: logger.info("Skipping Univariate Selection."); feats_sel_num = feats_uncorr
    feats_final = sorted(feats_sel_num + non_numeric_feats); logger.info(f"Feature selection complete. Selected {len(feats_final)} total features.")
    return X_train[feats_final].copy(), X_test[feats_final].copy(), feats_final

# --- Load Data ---
logger.info("Loading base data..."); 
try:
    metadata_df=pd.read_csv(METADATA_FILE); train_features_df=pd.read_csv(TRAIN_FEATURES_FILE); train_outcomes_df=pd.read_csv(TRAIN_OUTCOMES_FILE)
    test_features_df=pd.read_csv(TEST_FEATURES_FILE); submission_template_df=pd.read_csv(SUBMISSION_TEMPLATE_FILE)
    logger.warning("Replacing value 9 with NaN globally."); metadata_df.replace(9, np.nan, inplace=True); train_features_df.replace(9, np.nan, inplace=True); test_features_df.replace(9, np.nan, inplace=True)
except FileNotFoundError as e: logger.error(f"Error loading base data: {e}."); exit()
logger.info("Base data loaded.")

# --- Load External Motor Score Data ---
if USE_FUTURE_MOTOR_FEATURES:
    logger.info("Loading external future motor score data..."); 
    try:
        ext_preds_test_df=pd.read_csv(EXTERNAL_PREDS_FILE); logger.info(f"Loaded test preds: {EXTERNAL_PREDS_FILE} ({ext_preds_test_df.shape})")
        ext_actuals_train_df=pd.read_csv(TRAIN_OUTCOMES_MOTOR_FILE); logger.info(f"Loaded train actuals: {TRAIN_OUTCOMES_MOTOR_FILE} ({ext_actuals_train_df.shape})")
    except FileNotFoundError as e: logger.error(f"Error loading external motor data: {e}."); exit()
    motor_score_cols_ext=['elbfll','wrextl','elbexl','finfll','finabl','hipfll','kneexl','ankdol','gretol','ankpll','elbflr','wrextr','elbexr','finflr','finabr','hipflr','kneetr','ankdor','gretor','ankplr']
    if not all(col in ext_preds_test_df.columns for col in motor_score_cols_ext): logger.error(f"Missing motor cols in {EXTERNAL_PREDS_FILE}."); exit()
    if not all(col in ext_actuals_train_df.columns for col in motor_score_cols_ext): logger.error(f"Missing motor cols in {TRAIN_OUTCOMES_MOTOR_FILE}."); exit()
else: logger.info("Skipping loading external motor data."); ext_preds_test_df=None; ext_actuals_train_df=None; motor_score_cols_ext=[]

# --- Identify Initial Feature Groups ---
logger.info("Identifying initial feature groups..."); TARGET_COL='modben'
if TARGET_COL not in train_outcomes_df.columns: logger.error(f"Target '{TARGET_COL}' not found."); exit()
all_metadata_cols=[col for col in metadata_df.columns if col != 'PID']
all_train_week1_cols=[col for col in train_features_df.columns if re.search(r'01$', col) or col == 'ais1']
all_test_week1_cols=[col for col in test_features_df.columns if col not in ['PID']]
common_week1_cols=sorted(list(set(all_train_week1_cols).intersection(all_test_week1_cols)))
logger.info(f"Identified {len(all_metadata_cols)} metadata, {len(common_week1_cols)} common Wk1 cols.")

# --- Prepare Training Data (Initial Merge) ---
logger.info("Preparing training data (initial merge)...")
train_features_w1_df = train_features_df[['PID'] + common_week1_cols].copy()
train_merged_df = pd.merge(metadata_df, train_features_w1_df, on='PID', how='inner')

# --- Feature Engineering (from Week 1 data) ---
logger.info("Performing Feature Engineering (from Week 1 data)...")
def engineer_features(df, week1_feature_cols):
    eng_df = df.copy(); wk1_cols = [c for c in week1_feature_cols if c in df.columns]
    motor_cols = [c for c in wk1_cols if re.match(r'(?:elbf|wrext|elbex|finfl|finab|hipfl|kneex|ankdo|greto|ankpl)[lr]01$', c)]
    lt_cols = [c for c in wk1_cols if re.search(r'[cts]\d+lt[lr]01$', c) or re.search(r's45lt[lr]01$', c)]
    pp_cols = [c for c in wk1_cols if re.search(r'[cts]\d+pp[lr]01$', c) or re.search(r's45pp[lr]01$', c)]
    motor_l_cols=[c for c in motor_cols if c.endswith('l01')]; motor_r_cols=[c for c in motor_cols if c.endswith('r01')]
    lt_l_cols=[c for c in lt_cols if c.endswith('l01')]; lt_r_cols=[c for c in lt_cols if c.endswith('r01')]
    pp_l_cols=[c for c in pp_cols if c.endswith('l01')]; pp_r_cols=[c for c in pp_cols if c.endswith('r01')]
    uems_muscle_codes=['elbf','wrext','elbex','finfl','finab']; lems_muscle_codes=['hipfl','kneex','ankdo','greto','ankpl']
    uems_l_cols=[c for c in motor_l_cols if any(s in c for s in uems_muscle_codes)]; uems_r_cols=[c for c in motor_r_cols if any(s in c for s in uems_muscle_codes)]
    lems_l_cols=[c for c in motor_l_cols if any(s in c for s in lems_muscle_codes)]; lems_r_cols=[c for c in motor_r_cols if any(s in c for s in lems_muscle_codes)]
    if motor_cols:
        eng_df['FE_TotalMotor_Wk1'] = eng_df[motor_cols].sum(axis=1, skipna=False)
        if uems_l_cols or uems_r_cols: eng_df['FE_UEMS_Wk1'] = eng_df[uems_l_cols + uems_r_cols].sum(axis=1, skipna=False)
        if lems_l_cols or lems_r_cols: eng_df['FE_LEMS_Wk1'] = eng_df[lems_l_cols + lems_r_cols].sum(axis=1, skipna=False)
        if motor_l_cols: eng_df['FE_MotorL_Wk1'] = eng_df[motor_l_cols].sum(axis=1, skipna=False)
        if motor_r_cols: eng_df['FE_MotorR_Wk1'] = eng_df[motor_r_cols].sum(axis=1, skipna=False)
        if 'FE_MotorL_Wk1' in eng_df.columns and 'FE_MotorR_Wk1' in eng_df.columns: eng_df['FE_MotorSymmAbsDiff_Wk1'] = (eng_df['FE_MotorL_Wk1'] - eng_df['FE_MotorR_Wk1']).abs()
        eng_df['FE_MotorMean_Wk1'] = eng_df[motor_cols].mean(axis=1, skipna=True); eng_df['FE_MotorStd_Wk1'] = eng_df[motor_cols].std(axis=1, skipna=True)
        eng_df['FE_MotorMin_Wk1'] = eng_df[motor_cols].min(axis=1, skipna=True); eng_df['FE_MotorMax_Wk1'] = eng_df[motor_cols].max(axis=1, skipna=True)
    if lt_cols:
        eng_df['FE_TotalLTS_Wk1'] = eng_df[lt_cols].sum(axis=1, skipna=False)
        if lt_l_cols: eng_df['FE_LTS_L_Wk1'] = eng_df[lt_l_cols].sum(axis=1, skipna=False);
        if lt_r_cols: eng_df['FE_LTS_R_Wk1'] = eng_df[lt_r_cols].sum(axis=1, skipna=False)
        if 'FE_LTS_L_Wk1' in eng_df.columns and 'FE_LTS_R_Wk1' in eng_df.columns: eng_df['FE_LTSSymmAbsDiff_Wk1'] = (eng_df['FE_LTS_L_Wk1'] - eng_df['FE_LTS_R_Wk1']).abs()
        eng_df['FE_LTSMean_Wk1'] = eng_df[lt_cols].mean(axis=1, skipna=True); eng_df['FE_LTSStd_Wk1'] = eng_df[lt_cols].std(axis=1, skipna=True)
    if pp_cols:
        eng_df['FE_TotalPPS_Wk1'] = eng_df[pp_cols].sum(axis=1, skipna=False)
        if pp_l_cols: eng_df['FE_PPS_L_Wk1'] = eng_df[pp_l_cols].sum(axis=1, skipna=False)
        if pp_r_cols: eng_df['FE_PPS_R_Wk1'] = eng_df[pp_r_cols].sum(axis=1, skipna=False)
        if 'FE_PPS_L_Wk1' in eng_df.columns and 'FE_PPS_R_Wk1' in eng_df.columns: eng_df['FE_PPSSymmAbsDiff_Wk1'] = (eng_df['FE_PPS_L_Wk1'] - eng_df['FE_PPS_R_Wk1']).abs()
        eng_df['FE_PPSMean_Wk1'] = eng_df[pp_cols].mean(axis=1, skipna=True); eng_df['FE_PPSStd_Wk1'] = eng_df[pp_cols].std(axis=1, skipna=True)
    std_cols = [c for c in eng_df.columns if 'Std_Wk1' in c]; eng_df[std_cols] = eng_df[std_cols].fillna(0)
    logger.info(f"Shape after Wk1 FE: {eng_df.shape}"); return eng_df
X_train_merged_fe_wk1 = engineer_features(train_merged_df, common_week1_cols)
engineered_features_wk1 = sorted([col for col in X_train_merged_fe_wk1.columns if col.startswith('FE_') and col.endswith('_Wk1')])
logger.info(f"Identified {len(engineered_features_wk1)} Week 1 engineered features.")
gc.collect()

# --- Feature Engineering (from Future Motor Scores) ---
def engineer_future_motor_features(df, motor_score_cols): # <<< REMOVED suffix param
    """Applies feature engineering based on FUTURE motor scores (Wk26/52)."""
    SUFFIX = '_FutureMotor' # <<< USE CONSISTENT SUFFIX
    if df is None or not motor_score_cols: return pd.DataFrame()
    eng_df = df[['PID'] + motor_score_cols].copy()
    motor_cols = [c for c in motor_score_cols if c in eng_df.columns]
    if not motor_cols: return df[['PID']]
    motor_l_cols=[c for c in motor_cols if c.endswith('l')]; motor_r_cols=[c for c in motor_cols if c.endswith('r')]
    uems_muscle_codes_base=['elbf','wrext','elbex','finfl','finab']; lems_muscle_codes_base=['hipfl','kneex','ankdo','greto','ankpl']
    uems_l_cols=[f"{code}l" for code in uems_muscle_codes_base if f"{code}l" in motor_l_cols]; uems_r_cols=[f"{code}r" for code in uems_muscle_codes_base if f"{code}r" in motor_r_cols]
    lems_l_cols=[f"{code}l" for code in lems_muscle_codes_base if f"{code}l" in motor_l_cols]; lems_r_cols=[f"{code}r" for code in lems_muscle_codes_base if f"{code}r" in motor_r_cols]
    feature_prefix = 'FM_'; # Feature prefix remains
    eng_df[f'{feature_prefix}TotalMotor{SUFFIX}'] = eng_df[motor_cols].sum(axis=1, skipna=False) # <<< Use SUFFIX
    if uems_l_cols or uems_r_cols: eng_df[f'{feature_prefix}UEMS{SUFFIX}'] = eng_df[uems_l_cols + uems_r_cols].sum(axis=1, skipna=False) # <<< Use SUFFIX
    if lems_l_cols or lems_r_cols: eng_df[f'{feature_prefix}LEMS{SUFFIX}'] = eng_df[lems_l_cols + lems_r_cols].sum(axis=1, skipna=False) # <<< Use SUFFIX
    if motor_l_cols: eng_df[f'{feature_prefix}MotorL{SUFFIX}'] = eng_df[motor_l_cols].sum(axis=1, skipna=False) # <<< Use SUFFIX
    if motor_r_cols: eng_df[f'{feature_prefix}MotorR{SUFFIX}'] = eng_df[motor_r_cols].sum(axis=1, skipna=False) # <<< Use SUFFIX
    if f'{feature_prefix}MotorL{SUFFIX}' in eng_df.columns and f'{feature_prefix}MotorR{SUFFIX}' in eng_df.columns:
        eng_df[f'{feature_prefix}MotorSymmAbsDiff{SUFFIX}'] = (eng_df[f'{feature_prefix}MotorL{SUFFIX}'] - eng_df[f'{feature_prefix}MotorR{SUFFIX}']).abs() # <<< Use SUFFIX
    engineered_cols = [col for col in eng_df.columns if col.startswith(feature_prefix)]; logger.info(f"Generated {len(engineered_cols)} features (suffix: {SUFFIX}).")
    return eng_df[['PID'] + engineered_cols]
# Apply FE to external/actual motor scores
if USE_FUTURE_MOTOR_FEATURES:
    logger.info("Performing Feature Engineering (from Future Motor Scores)...")
    train_future_motor_features_df = engineer_future_motor_features(ext_actuals_train_df, motor_score_cols_ext) # <<< No suffix passed
    test_future_motor_features_df = engineer_future_motor_features(ext_preds_test_df, motor_score_cols_ext) # <<< No suffix passed
    # Identify features using the consistent suffix
    engineered_features_future = sorted([col for col in train_future_motor_features_df.columns if col.startswith('FM_') and col.endswith('_FutureMotor')])
    logger.info(f"Identified {len(engineered_features_future)} future motor engineered features.")
    logger.info("Merging future motor features into training data...")
    X_train_merged_fe_all = pd.merge(X_train_merged_fe_wk1, train_future_motor_features_df, on='PID', how='left')
    nan_check = X_train_merged_fe_all[engineered_features_future].isnull().sum().sum();
    if nan_check > 0: logger.warning(f"Found {nan_check} NaNs in future motor features after merge (train).")
else: engineered_features_future = []; X_train_merged_fe_all = X_train_merged_fe_wk1; logger.info("Skipping future motor FE.")
gc.collect()

# --- Select Initial Feature Set Based on Manual Configuration ---
# (Logic remains the same)
logger.info("Selecting initial feature set based on manual configuration...")
initial_features_selected = []
if SELECT_METADATA: initial_features_selected.extend(all_metadata_cols)
if SELECT_WEEK1_ORIGINAL: initial_features_selected.extend(common_week1_cols)
if SELECT_FE_FEATURES: initial_features_selected.extend(engineered_features_wk1)
if SELECT_FUTURE_MOTOR_FEATURES and USE_FUTURE_MOTOR_FEATURES: initial_features_selected.extend(engineered_features_future) # Adds features with _FutureMotor suffix
available_cols_in_merged_df = X_train_merged_fe_all.columns.tolist()
selected_features_manual = sorted(list(set([f for f in initial_features_selected if f in available_cols_in_merged_df])))
logger.info(f"Manually selected {len(selected_features_manual)} base features (before target_time/autoFS).")

# --- Prepare final X_train, y_train (using manually selected features) ---
# (Logic remains the same)
logger.info("Merging outcomes and finalizing training data (pre-autoFS)...")
train_full_df = pd.merge(X_train_merged_fe_all, train_outcomes_df[['PID', TARGET_COL, 'time']], on='PID', how='inner')
X_train_pre_fs = train_full_df[selected_features_manual].copy()
y_train_raw = train_full_df[TARGET_COL].copy(); time_train_raw = train_full_df['time'].copy()
valid_target_indices = y_train_raw.dropna().index; initial_rows = len(X_train_pre_fs)
X_train_pre_fs = X_train_pre_fs.loc[valid_target_indices].reset_index(drop=True)
y_train = y_train_raw.loc[valid_target_indices].reset_index(drop=True)
time_train = time_train_raw.loc[valid_target_indices].reset_index(drop=True)
final_rows = len(X_train_pre_fs); logger.info(f"Dropped {initial_rows - final_rows} rows with missing target.")
FEATURES_BEFORE_AUTOFS = selected_features_manual.copy()
if SELECT_TARGET_TIME: X_train_pre_fs['target_time'] = time_train; FEATURES_BEFORE_AUTOFS.append('target_time'); logger.info("Including 'target_time'.")
else: logger.info("Excluding 'target_time'.")
logger.info(f"Training data shape before autoFS: {X_train_pre_fs.shape}")

# --- Prepare Test Data (Apply FE, Merge External, Select Manual) ---
# (Logic remains the same - uses the consistent _FutureMotor suffix now)
logger.info("Preparing test data (pre-autoFS)...")
test_features_df_w1 = test_features_df[['PID'] + common_week1_cols].copy()
test_merged_df = pd.merge(metadata_df, test_features_df_w1, on='PID', how='inner')
X_test_merged_fe_wk1 = engineer_features(test_merged_df, common_week1_cols)
if USE_FUTURE_MOTOR_FEATURES: X_test_merged_fe_all = pd.merge(X_test_merged_fe_wk1, test_future_motor_features_df, on='PID', how='left') # Merges _FutureMotor cols
else: X_test_merged_fe_all = X_test_merged_fe_wk1
gc.collect()
submission_template_info = submission_template_df[['PID', 'time']].copy()
test_full_df = pd.merge(submission_template_info, X_test_merged_fe_all, on='PID', how='left')
test_PIDs = test_full_df['PID']; time_test = test_full_df['time']
# Select manually chosen base features (which now include _FutureMotor if selected)
X_test_pre_fs = test_full_df[selected_features_manual].copy()
if SELECT_TARGET_TIME: X_test_pre_fs['target_time'] = time_test
logger.info("Aligning columns pre-autoFS...")
missing_cols_test = set(FEATURES_BEFORE_AUTOFS) - set(X_test_pre_fs.columns)
extra_cols_test = set(X_test_pre_fs.columns) - set(FEATURES_BEFORE_AUTOFS)
if missing_cols_test: logger.warning(f"Cols missing pre-autoFS: {missing_cols_test}. Fill NaN."); [X_test_pre_fs.update({col: np.nan}) for col in missing_cols_test] # Use update for safety
if extra_cols_test: logger.warning(f"Cols extra pre-autoFS: {extra_cols_test}. Dropping."); X_test_pre_fs = X_test_pre_fs.drop(columns=list(extra_cols_test))
X_test_pre_fs = X_test_pre_fs[FEATURES_BEFORE_AUTOFS]
logger.info(f"Test data shape before autoFS: {X_test_pre_fs.shape}")


# --- Automated Feature Selection Step ---
# (Logic remains the same)
if DO_FEATURE_SELECTION:
    logger.info("--- Running Automated Feature Selection ---")
    X_train, X_test, FINAL_FEATURES_USED = select_features(
        X_train_pre_fs, y_train, X_test_pre_fs, FEATURES_BEFORE_AUTOFS,
        var_thresh=VAR_THRESH, corr_thresh=CORR_THRESH, k=UNIVARIATE_K
    )
    logger.info(f"--- Feature Selection Complete: {len(FINAL_FEATURES_USED)} features remaining ---")
else:
    logger.info("--- Skipping Automated Feature Selection ---")
    X_train = X_train_pre_fs.copy(); X_test = X_test_pre_fs.copy()
    FINAL_FEATURES_USED = FEATURES_BEFORE_AUTOFS
logger.info(f"Final data shapes for modeling: X_train={X_train.shape}, X_test={X_test.shape}")
if X_train.isnull().sum().sum() > 0: logger.warning(f"Final X_train contains {X_train.isnull().sum().sum()} NaNs.")
if X_test.isnull().sum().sum() > 0: logger.warning(f"Final X_test contains {X_test.isnull().sum().sum()} NaNs.")

# --- Preprocessing Pipeline (Based on FINAL_FEATURES_USED) ---
# (Logic remains the same)
logger.info(f"Setting up preprocessing pipeline for {len(FINAL_FEATURES_USED)} features...")
meta_categorical_base=['age_category','bmi_category','tx1_r','sexcd']; w1_ordinal_base=['ais1']; ais_categories=['A','B','C','D','E']
categorical_features = sorted([f for f in meta_categorical_base if f in FINAL_FEATURES_USED])
ordinal_features = sorted([f for f in w1_ordinal_base if f in FINAL_FEATURES_USED])
processed_cols = set(categorical_features + ordinal_features); numerical_features = sorted([col for col in FINAL_FEATURES_USED if col not in processed_cols])
logger.info(f"Encoding {len(categorical_features)} Cat: {categorical_features}"); logger.info(f"Encoding {len(ordinal_features)} Ord: {ordinal_features}"); logger.info(f"Passing {len(numerical_features)} Num.")
check_final=set(FINAL_FEATURES_USED); check_assigned=set(categorical_features+ordinal_features+numerical_features); assert check_final == check_assigned, f"Col mismatch! {check_final ^ check_assigned}"
cat_transformer = Pipeline(steps=[('imp', SimpleImputer(strategy='most_frequent', fill_value='missing')),('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])
if ordinal_features: ord_transformer = Pipeline(steps=[('imp', SimpleImputer(strategy='most_frequent')),('ord', OrdinalEncoder(categories=[ais_categories]*len(ordinal_features), handle_unknown='use_encoded_value', unknown_value=-1))])
else: ord_transformer = 'drop'
transformers_list = []
if categorical_features: transformers_list.append(('cat', cat_transformer, categorical_features))
if ordinal_features and ord_transformer != 'drop': transformers_list.append(('ord', ord_transformer, ordinal_features))
if numerical_features: transformers_list.append(('num', 'passthrough', numerical_features))
preprocessor = ColumnTransformer(transformers=transformers_list, remainder='drop', verbose_feature_names_out=False); preprocessor.set_output(transform="pandas")

# --- Define Model ---
# (Logic remains the same)
logger.info(f"Defining base {MODEL_TYPE} model structure...")
base_autotabpfn_estimator = AutoTabPFNRegressor(**{k: v for k, v in AUTOTABPFN_PARAMS.items() if k != 'random_state'})
base_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', base_autotabpfn_estimator)])

# --- Train Model (Averaging Loop or Single Run) ---
# (Logic remains the same)
all_test_predictions = []
if PERFORM_AVERAGING:
    logger.info(f"--- Mode: Training {N_AVERAGING_RUNS} {MODEL_TYPE} models ---")
    for i in range(N_AVERAGING_RUNS):
        current_run_seed = BASE_RANDOM_STATE + i; logger.info(f"--- Run {i+1}/{N_AVERAGING_RUNS} (Seed: {current_run_seed}) ---")
        current_pipeline = clone(base_pipeline); current_pipeline.set_params(regressor__random_state=current_run_seed)
        logger.info(f"Training... (Max time: {AUTO_TABPFN_TIME_BUDGET_SECONDS}s)"); start_time = datetime.datetime.now()
        try: current_pipeline.fit(X_train, y_train); end_time = datetime.datetime.now(); logger.info(f"Train complete. Time: {end_time - start_time}")
        except Exception as e: logger.error(f"ERROR train run {i+1}: {e}", exc_info=True); logger.warning(f"Skipping run {i+1}."); continue
        logger.info(f"Predicting run {i+1}..."); 
        try: current_predictions = current_pipeline.predict(X_test); all_test_predictions.append(current_predictions); logger.info("Predictions stored.")
        except Exception as e: logger.error(f"ERROR predict run {i+1}: {e}", exc_info=True); logger.warning(f"Skipping run {i+1}."); continue
        del current_pipeline, current_predictions; gc.collect()
    if not all_test_predictions: logger.error("No predictions generated. Exiting."); exit()
    logger.info(f"Averaging predictions across {len(all_test_predictions)} runs..."); final_predictions_raw = np.mean(all_test_predictions, axis=0); logger.info("Averaging complete.")
else: # Single Run
    logger.info(f"--- Mode: Training single {MODEL_TYPE} model ---"); final_pipeline_to_use = clone(base_pipeline); final_pipeline_to_use.set_params(regressor__random_state=BASE_RANDOM_STATE); logger.info(f"Using random_state={BASE_RANDOM_STATE}")
    if PERFORM_CV: # CV Block
        logger.info(f"--- Performing {CV_FOLDS}-Fold CV ---"); kf = KFold(n_splits=CV_FOLDS, shuffle=True, random_state=BASE_RANDOM_STATE); cv_n_jobs = 1
        logger.info(f"CV RMSE..."); 
        try: cv_scores_neg_rmse = cross_val_score(final_pipeline_to_use, X_train, y_train, cv=kf, scoring='neg_root_mean_squared_error', n_jobs=cv_n_jobs); mean_cv_rmse = np.mean(-cv_scores_neg_rmse); std_cv_rmse = np.std(-cv_scores_neg_rmse); logger.info(f"CV RMSE: {mean_cv_rmse:.4f} +/- {std_cv_rmse:.4f}")
        except Exception as e: logger.error(f"ERROR CV RMSE: {e}", exc_info=True)
        logger.info(f"CV Spearman..."); 
        try: cv_spearman_scores = cross_val_score(final_pipeline_to_use, X_train, y_train, cv=kf, scoring=spearman_scorer, n_jobs=cv_n_jobs); mean_cv_spearman = np.mean(cv_spearman_scores); std_cv_spearman = np.std(cv_spearman_scores); logger.info(f"CV Spearman Rho: {mean_cv_spearman:.4f} +/- {std_cv_spearman:.4f}")
        except Exception as e: logger.error(f"ERROR CV Spearman: {e}", exc_info=True)
        gc.collect()
    logger.info("Training final model..."); 
    try:
        start_time = datetime.datetime.now(); final_pipeline_to_use.fit(X_train, y_train); end_time = datetime.datetime.now(); logger.info(f"Training complete. Time: {end_time - start_time}")
        logger.info("Predicting..."); final_predictions_raw = final_pipeline_to_use.predict(X_test); logger.info("Predictions generated.")
    except Exception as e: logger.error(f"ERROR training/prediction: {e}", exc_info=True); num_test_samples = len(X_test); final_predictions_raw = np.full(num_test_samples, 1); logger.error("Dummy predictions generated.")

# --- Post-Process Final Predictions ---
# (Logic remains the same)
logger.info("Post-processing final predictions..."); 
try:
    MIN_SCORE = 1; MAX_SCORE = 8
    try: actual_min = int(y_train.min()); actual_max = int(y_train.max()); logger.info(f"Actual train target range: [{actual_min}, {actual_max}]")
    except Exception : logger.error("Could not get train target range.")
    final_predictions = final_predictions_raw.copy(); logger.info(f"Clipping predictions to [{MIN_SCORE}, {MAX_SCORE}] and rounding.")
    final_predictions = np.clip(final_predictions, MIN_SCORE, MAX_SCORE); final_predictions = np.round(final_predictions).astype(int); logger.info("Clamping and rounding complete.")
except Exception as e: logger.error(f"ERROR post-processing: {e}", exc_info=True); num_test_samples = len(X_test); final_predictions = np.full(num_test_samples, MIN_SCORE); logger.error("Using dummy predictions.")

# --- Generate Submission File ---
# (Logic remains the same)
logger.info("Generating submission file...")
predictions_df = pd.DataFrame({TARGET_COL: final_predictions}); submission_df = pd.DataFrame({'PID': test_PIDs, 'time': time_test})
submission_df.reset_index(drop=True, inplace=True); predictions_df.reset_index(drop=True, inplace=True); submission_df = pd.concat([submission_df, predictions_df], axis=1)
template_cols = submission_template_df.columns.tolist(); final_submission_df = pd.DataFrame(columns=template_cols)
try: final_submission_df[['PID', 'time']] = submission_df[['PID', 'time']]; final_submission_df[TARGET_COL] = submission_df[TARGET_COL]
except KeyError as e: logger.error(f"Col mismatch submission create: {e}."); final_submission_df = submission_df
if final_submission_df[TARGET_COL].isnull().any(): logger.warning(f"NaNs in submission target. Filling with {MIN_SCORE}."); final_submission_df[TARGET_COL].fillna(MIN_SCORE, inplace=True); final_submission_df[TARGET_COL] = final_submission_df[TARGET_COL].astype(int)
try: final_submission_df[template_cols].to_csv(SUBMISSION_OUTPUT_FILE, index=False); logger.info(f"Submission file saved to '{SUBMISSION_OUTPUT_FILE}'")
except KeyError as e: logger.error(f"ERROR saving submission file: Missing column {e}.")
except Exception as e: logger.error(f"ERROR saving submission file: {e}", exc_info=True)

# --- Log Run End ---
logger.info(f"--- Finished Run: {run_id} ---"); print(f"\nRun details logged to {log_file}")

# --- Final print statement ---
print(f"\nPipeline {MODEL_TYPE} (ManualFS={ms_str}, AutoFS={fs_str}, Avg={PERFORM_AVERAGING}) finished.")
print("Next steps:")
print(f"1. Review autoFS results in log ({log_file}). Adjust thresholds/k.")
print(f"2. Experiment with manual feature selection flags (SELECT_*)")
print("3. Review FE logic.")
print(f"4. Analyze performance & check log.")